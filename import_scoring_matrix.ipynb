{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "https://stackoverflow.com/questions/48470691/access-google-sheets-on-google-colaboratory\n",
        "\n",
        "https://colab.research.google.com/notebooks/io.ipynb#scrollTo=sOm9PFrT8mGG\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records\n",
        "\n"
      ],
      "metadata": {
        "id": "nDjee0DhlMht"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxIPWL_fe44S"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "import pandas as pd\n",
        "\n",
        "#authenticate google sheet\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gs = gspread.authorize(creds)\n",
        "\n",
        "#open the sheet scoring_matrix\n",
        "worksheet = gs.open(\"Scoring_matrix\").sheet1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "#create a df from the sheet\n",
        "df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "df\n",
        "\n",
        "#Create or update a table in GBQ\n",
        "#define project_id and dataset name\n",
        "project_id = 'transfermarkt-391212'\n",
        "dataset_name = 'personal_data'\n",
        "table_name = 'scoring_matrix'\n",
        "\n",
        "# Specify the destination table in BigQuery using the project, dataset, and table names\n",
        "destination_table = f'{project_id}.{dataset_name}.{table_name}'\n",
        "\n",
        "# Define the schema for each column in the DataFrame with the appropriate data types\n",
        "# Replace these with your actual column names and data types\n",
        "\n",
        "schema = {\n",
        "    'sub_position': 'object',\n",
        "    'total_match': 'int64',\n",
        "    'half_match': 'int64',\n",
        "    'goals': 'int64',\n",
        "    'assists': 'int64',\n",
        "    'yellow_cards': 'int64',\n",
        "    'red_cards': 'int64',\n",
        "    'goals_against': 'int64',\n",
        "    'bonus_clean_sheet': 'int64',\n",
        "    'bonus_no_yellow': 'int64',\n",
        "}\n",
        "\n",
        "# Cast the DataFrame columns to the specified data types\n",
        "\n",
        "for column, data_type in schema.items():\n",
        "    df[column] = df[column].astype(data_type)\n",
        "\n",
        "\n",
        "# Write the DataFrame to BigQuery, replace if the table already exists\n",
        "df.to_gbq(destination_table, project_id=project_id, if_exists='replace')\n",
        "\n",
        "print(\"table updated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIXKD6a9j5Y5",
        "outputId": "9054b0dc-434a-487e-e454-d308480ef1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1550.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "table updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}